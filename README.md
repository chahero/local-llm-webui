# Local LLM WebUI

[ğŸ‡ªğŸ‡¸ English](README.md) | [ğŸ‡°ğŸ‡· í•œêµ­ì–´](README.ko.md)

A modern web-based LLM interface that integrates with Ollama. Designed to make it easy to use large language models on your local machine.

## âœ¨ Key Features

- **ğŸ’¬ Real-time Streaming Chat** - Real-time conversation support with Ollama models
- **ğŸ” User Authentication** - Sign up/Login with SQLite database (bcrypt password hashing)
- **ğŸ’¾ Conversation History** - Save, load, rename, and delete conversations
- **ğŸ“Š Message Storage** - Store all messages, images, and metrics in database
- **ğŸ¤– Model Tracking** - Use multiple models in one conversation, track which model generated each response
- **âš¡ Performance Metrics** - Display token speed, generation time, prompt processing time, and model load time
- **ğŸ“¦ Model Management** - Install, delete, and download models
- **ğŸ–¼ï¸ Image Upload** - Send images with messages (drag and drop support)
- **ğŸ“ Markdown Rendering** - Display AI responses as markdown
- **ğŸ’» Code Highlighting** - Syntax highlighting for code blocks
- **ğŸ“± Responsive Design** - Perfect support for desktop and mobile
- **ğŸ¨ Modern UI** - Elegant dark theme based on Tailwind CSS

## ğŸ“‹ System Requirements

- Python 3.8+
- Ollama (Installation: https://ollama.ai)
- Minimum 4GB RAM (recommended: 8GB or more)

## ğŸš€ Installation

### 1. Clone the Repository
```bash
git clone <repository-url>
cd local-llm-webui
```

### 2. Install Python Dependencies
```bash
pip install -r requirements.txt
```

### 3. Environment Configuration
Edit the `.env` file (required):
```env
# Ollama server address
OLLAMA_API_URL=http://localhost:11434

# Flask settings
FLASK_DEBUG=True
SECRET_KEY=your-secret-key-here

# Server port
SERVER_PORT=5001

# SQLite settings
DATABASE_PATH=./instance/app.db
```

### 4. Run the Server
```bash
python main.py
```

Once the server starts, open your browser and navigate to:
```
http://localhost:5001
```

## ğŸ’¡ Usage

### First Run
1. Click "Sign Up" on the login page
2. Create a new account (username, password)
3. Log in

### Chat Usage
1. Select a model from the top of the page
2. Enter your message and press **Enter** or click the send button
3. **Shift + Enter** - Create a new line in the message input

### Image Upload
- Click the ğŸ–¼ï¸ button to select an image
- Or drag and drop an image into the message area
- Or paste an image from clipboard with Ctrl+V

### Model Management
1. Click the "âš™ï¸ Model Management" button in the top right
2. **Installed Models** - View and delete currently installed models
3. **Download Model** - Install new models (e.g., llama2, mistral, neural-chat)

## ğŸ“ Project Structure

```
local-llm-webui/
â”œâ”€â”€ main.py                 # Flask application entry point
â”œâ”€â”€ config.py              # Configuration file
â”œâ”€â”€ models.py              # SQLAlchemy User model
â”œâ”€â”€ requirements.txt       # Python dependencies
â”œâ”€â”€ .env                   # Environment variable settings
â”œâ”€â”€ instance/app.db                 # SQLite database (auto-created)
â”œâ”€â”€ routes/
â”‚   â”œâ”€â”€ api.py            # Chat/model management API
â”‚   â””â”€â”€ auth.py           # Authentication API (login/logout)
â”œâ”€â”€ utils/
â”‚   â”œâ”€â”€ ollama_client.py  # Ollama API client
â”‚   â””â”€â”€ decorators.py     # Login-required decorator
â”œâ”€â”€ templates/
â”‚   â”œâ”€â”€ index.html        # Chat page
â”‚   â””â”€â”€ login.html        # Login page
â””â”€â”€ static/
    â”œâ”€â”€ css/
    â”‚   â””â”€â”€ style.css     # (Replaced with Tailwind CSS)
    â””â”€â”€ js/
        â””â”€â”€ app.js        # Frontend logic
```

## ğŸ”§ API Endpoints

### Authentication
- `POST /api/auth/login` - Login
- `POST /api/auth/logout` - Logout (login required)
- `GET /api/auth/check` - Check login status
- `POST /api/auth/register` - Register

### Chat & Models
- `GET /api/health` - Check Ollama server status (login required)
- `GET /api/models` - List models (login required)
- `POST /api/chat` - Chat with streaming (login required)
- `POST /api/save-message` - Save AI response message (login required)
- `POST /api/pull` - Download model (login required)
- `POST /api/delete` - Delete model (login required)

### Conversation History
- `GET /api/conversations` - Get all user conversations (login required)
- `POST /api/conversations` - Create new conversation (login required)
- `GET /api/conversations/{id}` - Get specific conversation with messages (login required)
- `PUT /api/conversations/{id}/title` - Update conversation title (login required)
- `DELETE /api/conversations/{id}` - Delete conversation (soft delete, login required)

## âš™ï¸ Configuration Options

### .env File Description

| Variable | Description | Default |
|----------|-------------|---------|
| OLLAMA_API_URL | Ollama server address | http://localhost:11434 |
| FLASK_DEBUG | Flask Debug mode | True |
| SECRET_KEY | Flask session encryption key | dev-secret-key |
| SERVER_PORT | Web server port | 5001 |
| DATABASE_PATH | SQLite DB path | ./instance/app.db |

## ğŸ”’ Security

- **Passwords**: Securely stored with bcrypt hashing
- **Sessions**: Login state managed with Flask sessions
- **XSS Prevention**: User input validated with DOMPurify
- **CSRF**: Basic Flask CSRF protection

> âš ï¸ **Warning**: This is a development environment. Additional security measures are required for production deployment.

## ğŸ› Troubleshooting

### Ollama Connection Failed
```
Error: "Cannot connect to Ollama server"
Solution:
1. Verify Ollama server is running
2. Check that OLLAMA_API_URL is correct
3. Check firewall settings
```

### Model Download Failed
```
Error: "Download failed"
Solution:
1. Check internet connection
2. Verify model name (https://ollama.ai/library)
3. Check available disk space
```

### Database Reset
```bash
rm instance/app.db
python main.py  # New database will be created automatically
```

## ğŸ¨ UI Tech Stack

- **HTML5** - Structure
- **Tailwind CSS** - Styling (CDN)
- **JavaScript** - Interactions
- **Marked.js** - Markdown parsing
- **Highlight.js** - Code highlighting
- **DOMPurify** - XSS prevention

## ğŸ› ï¸ Development Mode

Already enabled features:
- âœ… Debug mode (`debug=True`)
- âœ… Auto-reload (automatically restarts on file changes)
- âœ… Detailed error messages

The server will automatically restart when you modify Python files.

## ğŸ“ Changelog

### v1.1.0
- **Conversation History** - Save, load, rename, and delete conversations
- **Message Storage** - Store all messages, images, and metrics in database
- **Model Tracking** - Track which model generated each response in multi-model conversations
- **Performance Metrics** - Display token speed, generation time, prompt processing time, and model load time
- **UI Improvements** - Beautiful gradient-styled delete button
- **UX Enhancements** - Integrated model information with metrics display

### v1.0.0
- UI redesign with Tailwind CSS
- Login/authentication system added
- Streaming chat implemented
- Mobile responsive support

## ğŸ“„ License

MIT License

## ğŸ¤ Contributing

Please report bugs or suggest features through issues.

## â“ FAQ

**Q: How do I install models?**
A: Go to Model Management â†’ Download Model and enter the model name. It will install automatically. (e.g., llama2, mistral)

**Q: Does it support multiple users?**
A: Yes, each user can log in with their own account. Each user's conversation history and messages are managed separately.

**Q: Can I use multiple models in one conversation?**
A: Yes! You can switch models within the same conversation. Each AI response automatically records which model was used, so you can compare responses from different models.

**Q: Can I view previous conversations?**
A: Yes, click on any conversation in the left sidebar to load the full message history. Conversations are automatically sorted by date.

**Q: Where can I see performance information?**
A: Performance metrics are displayed below each AI response, including token speed, generation time, prompt processing time, and model load time.

**Q: Can I deploy to a remote server?**
A: Yes, but production configuration is required. It's recommended to change `SECRET_KEY` and set up HTTPS.

**Q: Which models do you recommend?**
A: Beginner: llama2, mistral / Advanced: neural-chat, orca-mini

---

**Created**: November 2025
**Version**: 1.1.0

